{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Fact-checking project using pandas and ScikitLearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Travail réalisé par : Bouali Mohammed-Amin, Oussama Nassim Sehout, Chahinez Benallal, Abdellah Choukri \n",
    "\n",
    "\n",
    "\n",
    "####  Sommaire du travail :\n",
    "####   . Chargement du jeu de données\n",
    "####   . Prétraitement du texte \n",
    "###   . Conversion des textes aux valeurs numériques\n",
    "###   . Division du jeu de données en données d'entraînement et données de test\n",
    "###   . Entraînement et prédiction en utilisant des modèles de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 1 : Chargement du jeu de données  \n",
    " On a généré trois fichiers csv, un avec valeurs true, un autre avec valeurs false, et un dernier avec valeurs mixture à partir du site ClaimsKg, après on les concatène pour avoir notre jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataframe :342328 (24452*14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>truthRating</th>\n",
       "      <th>ratingName</th>\n",
       "      <th>author</th>\n",
       "      <th>headline</th>\n",
       "      <th>named_entities_claim</th>\n",
       "      <th>named_entities_article</th>\n",
       "      <th>keywords</th>\n",
       "      <th>source</th>\n",
       "      <th>sourceURL</th>\n",
       "      <th>link</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/47...</td>\n",
       "      <td>'Hillary's main extracurricular activity in la...</td>\n",
       "      <td>2008-01-24</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Chain email</td>\n",
       "      <td>She did not \"\"help\"\" the Black Panthers</td>\n",
       "      <td>ACLU,Alex Rackley,American Civil Liberties Uni...</td>\n",
       "      <td>Black Panthers</td>\n",
       "      <td>Candidate Biography</td>\n",
       "      <td>politifact</td>\n",
       "      <td>http://www.politifact.com</td>\n",
       "      <td>http://www.politifact.com/truth-o-meter/statem...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/1d...</td>\n",
       "      <td>Says 'Hillary Clinton's plan would bring in 62...</td>\n",
       "      <td>2016-09-20</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Trump says Clinton would bring in 620,000 refu...</td>\n",
       "      <td>Barack Obama,CBS,Center for Global Development...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>Immigration</td>\n",
       "      <td>politifact</td>\n",
       "      <td>http://www.politifact.com</td>\n",
       "      <td>http://www.politifact.com/truth-o-meter/statem...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/51...</td>\n",
       "      <td>Canada suffered a major donut shortage shortly...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Did Canadians Face a Major Donut Shortage Afte...</td>\n",
       "      <td>CNN,Daily Bonnet,Girl Scout cookies,Tim Horton...</td>\n",
       "      <td>marijuana</td>\n",
       "      <td>canada, marijuana, world news daily report</td>\n",
       "      <td>snopes</td>\n",
       "      <td>http://www.snopes.com</td>\n",
       "      <td>https://www.snopes.com/fact-check/canada-donut...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/c5...</td>\n",
       "      <td>The mayor of Ath, in Belgium, refused to remov...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Did a Belgian Mayor Refuse to Ban Pork in Scho...</td>\n",
       "      <td>Belgium,Islam,Maryborough, Victoria,Muslim,Que...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>islam</td>\n",
       "      <td>snopes</td>\n",
       "      <td>http://www.snopes.com</td>\n",
       "      <td>https://www.snopes.com/fact-check/belgium-mayo...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/ef...</td>\n",
       "      <td>Says Pete Gallego canceled a 'planned meeting ...</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Roland Gutierrez</td>\n",
       "      <td>Roland Gutierrez errs saying Pete Gallego canc...</td>\n",
       "      <td>2012 mass shooting,Carlos Uresti,Democrat,Face...</td>\n",
       "      <td>Pete Gallego</td>\n",
       "      <td>Congress,Guns</td>\n",
       "      <td>politifact</td>\n",
       "      <td>http://www.politifact.com</td>\n",
       "      <td>http://www.politifact.com/texas/statements/201...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4447</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/d7...</td>\n",
       "      <td>A pedestrian was killed by a flying fire hydrant.</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Fire Hydrant Death</td>\n",
       "      <td>Associated Press,Encinitas, California,Fire Hy...</td>\n",
       "      <td>fire hydrant</td>\n",
       "      <td>ASP Article, freakish fatalities</td>\n",
       "      <td>snopes</td>\n",
       "      <td>http://www.snopes.com</td>\n",
       "      <td>https://www.snopes.com/fact-check/fire-plugged/</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4448</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/b5...</td>\n",
       "      <td>'The United States is the ONLY industrialized ...</td>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>Mark Pocan</td>\n",
       "      <td>Universal health care diagnosis is on the mark</td>\n",
       "      <td>Affordable Care Act,Australia,Austria,Belarus,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Health Care,Medicaid,Medicare</td>\n",
       "      <td>politifact</td>\n",
       "      <td>http://www.politifact.com</td>\n",
       "      <td>http://www.politifact.com/wisconsin/statements...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4449</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/05...</td>\n",
       "      <td>A 17-year-old Nigerian girl was publicly flogg...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Bariya Ibrahim Magazu Petition</td>\n",
       "      <td>Abuja,Associated Press,Barbara “faith,Dallas M...</td>\n",
       "      <td>premarital sex</td>\n",
       "      <td>ASP Article, Petitions</td>\n",
       "      <td>snopes</td>\n",
       "      <td>http://www.snopes.com</td>\n",
       "      <td>https://www.snopes.com/fact-check/the-cane-mut...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/7d...</td>\n",
       "      <td>'We haven’t had control of the House for the l...</td>\n",
       "      <td>2010-10-18</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>William G. Batchelder</td>\n",
       "      <td>Republican state Rep. Bill Batchelder knocks D...</td>\n",
       "      <td>Armond Budish,Democrat,PolitiFact,Republican</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Government Efficiency</td>\n",
       "      <td>politifact</td>\n",
       "      <td>http://www.politifact.com</td>\n",
       "      <td>http://www.politifact.com/ohio/statements/2010...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4451</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/57...</td>\n",
       "      <td>Saudi Arabia is 'the only Muslim country out o...</td>\n",
       "      <td>2014-10-06</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>Dean Obeidallah</td>\n",
       "      <td>Obeidallah: Saudi Arabia is the only Muslim na...</td>\n",
       "      <td>Bill Maher,Dean Obeidallah,Ed Show,Georgetown ...</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>Islam</td>\n",
       "      <td>politifact</td>\n",
       "      <td>http://www.politifact.com</td>\n",
       "      <td>http://www.politifact.com/punditfact/statement...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24452 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id  \\\n",
       "0     http://data.gesis.org/claimskg/claim_review/47...   \n",
       "1     http://data.gesis.org/claimskg/claim_review/1d...   \n",
       "2     http://data.gesis.org/claimskg/claim_review/51...   \n",
       "3     http://data.gesis.org/claimskg/claim_review/c5...   \n",
       "4     http://data.gesis.org/claimskg/claim_review/ef...   \n",
       "...                                                 ...   \n",
       "4447  http://data.gesis.org/claimskg/claim_review/d7...   \n",
       "4448  http://data.gesis.org/claimskg/claim_review/b5...   \n",
       "4449  http://data.gesis.org/claimskg/claim_review/05...   \n",
       "4450  http://data.gesis.org/claimskg/claim_review/7d...   \n",
       "4451  http://data.gesis.org/claimskg/claim_review/57...   \n",
       "\n",
       "                                                   text        date  \\\n",
       "0     'Hillary's main extracurricular activity in la...  2008-01-24   \n",
       "1     Says 'Hillary Clinton's plan would bring in 62...  2016-09-20   \n",
       "2     Canada suffered a major donut shortage shortly...     Unknown   \n",
       "3     The mayor of Ath, in Belgium, refused to remov...     Unknown   \n",
       "4     Says Pete Gallego canceled a 'planned meeting ...  2018-07-18   \n",
       "...                                                 ...         ...   \n",
       "4447  A pedestrian was killed by a flying fire hydrant.     Unknown   \n",
       "4448  'The United States is the ONLY industrialized ...  2019-04-30   \n",
       "4449  A 17-year-old Nigerian girl was publicly flogg...     Unknown   \n",
       "4450  'We haven’t had control of the House for the l...  2010-10-18   \n",
       "4451  Saudi Arabia is 'the only Muslim country out o...  2014-10-06   \n",
       "\n",
       "      truthRating ratingName                 author  \\\n",
       "0               1      False            Chain email   \n",
       "1               1      False           Donald Trump   \n",
       "2               1      False                Unknown   \n",
       "3               1      False                Unknown   \n",
       "4               1      False       Roland Gutierrez   \n",
       "...           ...        ...                    ...   \n",
       "4447            3       True                Unknown   \n",
       "4448            3       True             Mark Pocan   \n",
       "4449            3       True                Unknown   \n",
       "4450            3       True  William G. Batchelder   \n",
       "4451            3       True        Dean Obeidallah   \n",
       "\n",
       "                                               headline  \\\n",
       "0               She did not \"\"help\"\" the Black Panthers   \n",
       "1     Trump says Clinton would bring in 620,000 refu...   \n",
       "2     Did Canadians Face a Major Donut Shortage Afte...   \n",
       "3     Did a Belgian Mayor Refuse to Ban Pork in Scho...   \n",
       "4     Roland Gutierrez errs saying Pete Gallego canc...   \n",
       "...                                                 ...   \n",
       "4447                                 Fire Hydrant Death   \n",
       "4448     Universal health care diagnosis is on the mark   \n",
       "4449                     Bariya Ibrahim Magazu Petition   \n",
       "4450  Republican state Rep. Bill Batchelder knocks D...   \n",
       "4451  Obeidallah: Saudi Arabia is the only Muslim na...   \n",
       "\n",
       "                                   named_entities_claim  \\\n",
       "0     ACLU,Alex Rackley,American Civil Liberties Uni...   \n",
       "1     Barack Obama,CBS,Center for Global Development...   \n",
       "2     CNN,Daily Bonnet,Girl Scout cookies,Tim Horton...   \n",
       "3     Belgium,Islam,Maryborough, Victoria,Muslim,Que...   \n",
       "4     2012 mass shooting,Carlos Uresti,Democrat,Face...   \n",
       "...                                                 ...   \n",
       "4447  Associated Press,Encinitas, California,Fire Hy...   \n",
       "4448  Affordable Care Act,Australia,Austria,Belarus,...   \n",
       "4449  Abuja,Associated Press,Barbara “faith,Dallas M...   \n",
       "4450       Armond Budish,Democrat,PolitiFact,Republican   \n",
       "4451  Bill Maher,Dean Obeidallah,Ed Show,Georgetown ...   \n",
       "\n",
       "     named_entities_article                                    keywords  \\\n",
       "0            Black Panthers                         Candidate Biography   \n",
       "1           Hillary Clinton                                 Immigration   \n",
       "2                 marijuana  canada, marijuana, world news daily report   \n",
       "3                       NaN                                       islam   \n",
       "4              Pete Gallego                               Congress,Guns   \n",
       "...                     ...                                         ...   \n",
       "4447           fire hydrant            ASP Article, freakish fatalities   \n",
       "4448                    NaN               Health Care,Medicaid,Medicare   \n",
       "4449         premarital sex                      ASP Article, Petitions   \n",
       "4450                    NaN                       Government Efficiency   \n",
       "4451           Saudi Arabia                                       Islam   \n",
       "\n",
       "          source                  sourceURL  \\\n",
       "0     politifact  http://www.politifact.com   \n",
       "1     politifact  http://www.politifact.com   \n",
       "2         snopes      http://www.snopes.com   \n",
       "3         snopes      http://www.snopes.com   \n",
       "4     politifact  http://www.politifact.com   \n",
       "...          ...                        ...   \n",
       "4447      snopes      http://www.snopes.com   \n",
       "4448  politifact  http://www.politifact.com   \n",
       "4449      snopes      http://www.snopes.com   \n",
       "4450  politifact  http://www.politifact.com   \n",
       "4451  politifact  http://www.politifact.com   \n",
       "\n",
       "                                                   link language  \n",
       "0     http://www.politifact.com/truth-o-meter/statem...  English  \n",
       "1     http://www.politifact.com/truth-o-meter/statem...  English  \n",
       "2     https://www.snopes.com/fact-check/canada-donut...  English  \n",
       "3     https://www.snopes.com/fact-check/belgium-mayo...  English  \n",
       "4     http://www.politifact.com/texas/statements/201...  English  \n",
       "...                                                 ...      ...  \n",
       "4447    https://www.snopes.com/fact-check/fire-plugged/  English  \n",
       "4448  http://www.politifact.com/wisconsin/statements...  English  \n",
       "4449  https://www.snopes.com/fact-check/the-cane-mut...  English  \n",
       "4450  http://www.politifact.com/ohio/statements/2010...  English  \n",
       "4451  http://www.politifact.com/punditfact/statement...  English  \n",
       "\n",
       "[24452 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random as random\n",
    "import glob, os\n",
    "\n",
    "#concatener les fichiers en python  et lecture du fichier :\n",
    "df = pd.concat(map(pd.read_csv, glob.glob(os.path.join('', \"./DataSet/*.csv\"))))\n",
    "\n",
    "row, col = df.shape\n",
    "print(\"Size of the dataframe :\" + str(df.size) + \" (\"+str(row)+\"*\"+str(col)+\")\")\n",
    "\n",
    "df.head()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 2 : Prétraitement du texte\n",
    " On a fait les prétraitements suivants :\n",
    "     . Transformation du texte en miniscule\n",
    "     . Suppression des espaces\n",
    "     . Enlever les ponctuations \n",
    "     . Elimination des stopwords\n",
    "     . Remplacement des mots de négation par le mot 'not'\n",
    "     . Suppression des caractères non ASCII\n",
    "     . Lemmatization \n",
    "     . Correction orthographique ##TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Chahinez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Chahinez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Chahinez\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most common word[('say', 4888), ('s', 3903), ('not', 2872), ('state', 2269), ('president', 1825), ('obama', 1699), ('percent', 1672), ('show', 1558), ('tax', 1509), ('trump', 1433)]\n",
      "Suppression of the common word de nos artiles : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>truthRating</th>\n",
       "      <th>ratingName</th>\n",
       "      <th>author</th>\n",
       "      <th>headline</th>\n",
       "      <th>named_entities_claim</th>\n",
       "      <th>named_entities_article</th>\n",
       "      <th>keywords</th>\n",
       "      <th>source</th>\n",
       "      <th>sourceURL</th>\n",
       "      <th>link</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/47...</td>\n",
       "      <td>hillary main extracurricular activity law scho...</td>\n",
       "      <td>2008-01-24</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Chain email</td>\n",
       "      <td>She did not \"\"help\"\" the Black Panthers</td>\n",
       "      <td>ACLU,Alex Rackley,American Civil Liberties Uni...</td>\n",
       "      <td>Black Panthers</td>\n",
       "      <td>Candidate Biography</td>\n",
       "      <td>politifact</td>\n",
       "      <td>http://www.politifact.com</td>\n",
       "      <td>http://www.politifact.com/truth-o-meter/statem...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/1d...</td>\n",
       "      <td>hillary clinton plan would bring refugees firs...</td>\n",
       "      <td>2016-09-20</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Donald Trump</td>\n",
       "      <td>Trump says Clinton would bring in 620,000 refu...</td>\n",
       "      <td>Barack Obama,CBS,Center for Global Development...</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>Immigration</td>\n",
       "      <td>politifact</td>\n",
       "      <td>http://www.politifact.com</td>\n",
       "      <td>http://www.politifact.com/truth-o-meter/statem...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/51...</td>\n",
       "      <td>canada suffer major donut shortage shortly cou...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Did Canadians Face a Major Donut Shortage Afte...</td>\n",
       "      <td>CNN,Daily Bonnet,Girl Scout cookies,Tim Horton...</td>\n",
       "      <td>marijuana</td>\n",
       "      <td>canada, marijuana, world news daily report</td>\n",
       "      <td>snopes</td>\n",
       "      <td>http://www.snopes.com</td>\n",
       "      <td>https://www.snopes.com/fact-check/canada-donut...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/c5...</td>\n",
       "      <td>mayor ath belgium refuse remove pork school ca...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Did a Belgian Mayor Refuse to Ban Pork in Scho...</td>\n",
       "      <td>Belgium,Islam,Maryborough, Victoria,Muslim,Que...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>islam</td>\n",
       "      <td>snopes</td>\n",
       "      <td>http://www.snopes.com</td>\n",
       "      <td>https://www.snopes.com/fact-check/belgium-mayo...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/ef...</td>\n",
       "      <td>pete gallego cancel plan meet families sandy h...</td>\n",
       "      <td>2018-07-18</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Roland Gutierrez</td>\n",
       "      <td>Roland Gutierrez errs saying Pete Gallego canc...</td>\n",
       "      <td>2012 mass shooting,Carlos Uresti,Democrat,Face...</td>\n",
       "      <td>Pete Gallego</td>\n",
       "      <td>Congress,Guns</td>\n",
       "      <td>politifact</td>\n",
       "      <td>http://www.politifact.com</td>\n",
       "      <td>http://www.politifact.com/texas/statements/201...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4447</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/d7...</td>\n",
       "      <td>pedestrian kill fly fire hydrant</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Fire Hydrant Death</td>\n",
       "      <td>Associated Press,Encinitas, California,Fire Hy...</td>\n",
       "      <td>fire hydrant</td>\n",
       "      <td>ASP Article, freakish fatalities</td>\n",
       "      <td>snopes</td>\n",
       "      <td>http://www.snopes.com</td>\n",
       "      <td>https://www.snopes.com/fact-check/fire-plugged/</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4448</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/b5...</td>\n",
       "      <td>unite industrialize country without universal ...</td>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>Mark Pocan</td>\n",
       "      <td>Universal health care diagnosis is on the mark</td>\n",
       "      <td>Affordable Care Act,Australia,Austria,Belarus,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Health Care,Medicaid,Medicare</td>\n",
       "      <td>politifact</td>\n",
       "      <td>http://www.politifact.com</td>\n",
       "      <td>http://www.politifact.com/wisconsin/statements...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4449</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/05...</td>\n",
       "      <td>yearold nigerian girl publicly flog engage pre...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Bariya Ibrahim Magazu Petition</td>\n",
       "      <td>Abuja,Associated Press,Barbara “faith,Dallas M...</td>\n",
       "      <td>premarital sex</td>\n",
       "      <td>ASP Article, Petitions</td>\n",
       "      <td>snopes</td>\n",
       "      <td>http://www.snopes.com</td>\n",
       "      <td>https://www.snopes.com/fact-check/the-cane-mut...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/7d...</td>\n",
       "      <td>control house last two years malfunction sessi...</td>\n",
       "      <td>2010-10-18</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>William G. Batchelder</td>\n",
       "      <td>Republican state Rep. Bill Batchelder knocks D...</td>\n",
       "      <td>Armond Budish,Democrat,PolitiFact,Republican</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Government Efficiency</td>\n",
       "      <td>politifact</td>\n",
       "      <td>http://www.politifact.com</td>\n",
       "      <td>http://www.politifact.com/ohio/statements/2010...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4451</td>\n",
       "      <td>http://data.gesis.org/claimskg/claim_review/57...</td>\n",
       "      <td>saudi arabia muslim country muslimmajority cou...</td>\n",
       "      <td>2014-10-06</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>Dean Obeidallah</td>\n",
       "      <td>Obeidallah: Saudi Arabia is the only Muslim na...</td>\n",
       "      <td>Bill Maher,Dean Obeidallah,Ed Show,Georgetown ...</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>Islam</td>\n",
       "      <td>politifact</td>\n",
       "      <td>http://www.politifact.com</td>\n",
       "      <td>http://www.politifact.com/punditfact/statement...</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24452 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     id  \\\n",
       "0     http://data.gesis.org/claimskg/claim_review/47...   \n",
       "1     http://data.gesis.org/claimskg/claim_review/1d...   \n",
       "2     http://data.gesis.org/claimskg/claim_review/51...   \n",
       "3     http://data.gesis.org/claimskg/claim_review/c5...   \n",
       "4     http://data.gesis.org/claimskg/claim_review/ef...   \n",
       "...                                                 ...   \n",
       "4447  http://data.gesis.org/claimskg/claim_review/d7...   \n",
       "4448  http://data.gesis.org/claimskg/claim_review/b5...   \n",
       "4449  http://data.gesis.org/claimskg/claim_review/05...   \n",
       "4450  http://data.gesis.org/claimskg/claim_review/7d...   \n",
       "4451  http://data.gesis.org/claimskg/claim_review/57...   \n",
       "\n",
       "                                                   text        date  \\\n",
       "0     hillary main extracurricular activity law scho...  2008-01-24   \n",
       "1     hillary clinton plan would bring refugees firs...  2016-09-20   \n",
       "2     canada suffer major donut shortage shortly cou...     Unknown   \n",
       "3     mayor ath belgium refuse remove pork school ca...     Unknown   \n",
       "4     pete gallego cancel plan meet families sandy h...  2018-07-18   \n",
       "...                                                 ...         ...   \n",
       "4447                   pedestrian kill fly fire hydrant     Unknown   \n",
       "4448  unite industrialize country without universal ...  2019-04-30   \n",
       "4449  yearold nigerian girl publicly flog engage pre...     Unknown   \n",
       "4450  control house last two years malfunction sessi...  2010-10-18   \n",
       "4451  saudi arabia muslim country muslimmajority cou...  2014-10-06   \n",
       "\n",
       "      truthRating ratingName                 author  \\\n",
       "0               1      False            Chain email   \n",
       "1               1      False           Donald Trump   \n",
       "2               1      False                Unknown   \n",
       "3               1      False                Unknown   \n",
       "4               1      False       Roland Gutierrez   \n",
       "...           ...        ...                    ...   \n",
       "4447            3       True                Unknown   \n",
       "4448            3       True             Mark Pocan   \n",
       "4449            3       True                Unknown   \n",
       "4450            3       True  William G. Batchelder   \n",
       "4451            3       True        Dean Obeidallah   \n",
       "\n",
       "                                               headline  \\\n",
       "0               She did not \"\"help\"\" the Black Panthers   \n",
       "1     Trump says Clinton would bring in 620,000 refu...   \n",
       "2     Did Canadians Face a Major Donut Shortage Afte...   \n",
       "3     Did a Belgian Mayor Refuse to Ban Pork in Scho...   \n",
       "4     Roland Gutierrez errs saying Pete Gallego canc...   \n",
       "...                                                 ...   \n",
       "4447                                 Fire Hydrant Death   \n",
       "4448     Universal health care diagnosis is on the mark   \n",
       "4449                     Bariya Ibrahim Magazu Petition   \n",
       "4450  Republican state Rep. Bill Batchelder knocks D...   \n",
       "4451  Obeidallah: Saudi Arabia is the only Muslim na...   \n",
       "\n",
       "                                   named_entities_claim  \\\n",
       "0     ACLU,Alex Rackley,American Civil Liberties Uni...   \n",
       "1     Barack Obama,CBS,Center for Global Development...   \n",
       "2     CNN,Daily Bonnet,Girl Scout cookies,Tim Horton...   \n",
       "3     Belgium,Islam,Maryborough, Victoria,Muslim,Que...   \n",
       "4     2012 mass shooting,Carlos Uresti,Democrat,Face...   \n",
       "...                                                 ...   \n",
       "4447  Associated Press,Encinitas, California,Fire Hy...   \n",
       "4448  Affordable Care Act,Australia,Austria,Belarus,...   \n",
       "4449  Abuja,Associated Press,Barbara “faith,Dallas M...   \n",
       "4450       Armond Budish,Democrat,PolitiFact,Republican   \n",
       "4451  Bill Maher,Dean Obeidallah,Ed Show,Georgetown ...   \n",
       "\n",
       "     named_entities_article                                    keywords  \\\n",
       "0            Black Panthers                         Candidate Biography   \n",
       "1           Hillary Clinton                                 Immigration   \n",
       "2                 marijuana  canada, marijuana, world news daily report   \n",
       "3                       NaN                                       islam   \n",
       "4              Pete Gallego                               Congress,Guns   \n",
       "...                     ...                                         ...   \n",
       "4447           fire hydrant            ASP Article, freakish fatalities   \n",
       "4448                    NaN               Health Care,Medicaid,Medicare   \n",
       "4449         premarital sex                      ASP Article, Petitions   \n",
       "4450                    NaN                       Government Efficiency   \n",
       "4451           Saudi Arabia                                       Islam   \n",
       "\n",
       "          source                  sourceURL  \\\n",
       "0     politifact  http://www.politifact.com   \n",
       "1     politifact  http://www.politifact.com   \n",
       "2         snopes      http://www.snopes.com   \n",
       "3         snopes      http://www.snopes.com   \n",
       "4     politifact  http://www.politifact.com   \n",
       "...          ...                        ...   \n",
       "4447      snopes      http://www.snopes.com   \n",
       "4448  politifact  http://www.politifact.com   \n",
       "4449      snopes      http://www.snopes.com   \n",
       "4450  politifact  http://www.politifact.com   \n",
       "4451  politifact  http://www.politifact.com   \n",
       "\n",
       "                                                   link language  \n",
       "0     http://www.politifact.com/truth-o-meter/statem...  English  \n",
       "1     http://www.politifact.com/truth-o-meter/statem...  English  \n",
       "2     https://www.snopes.com/fact-check/canada-donut...  English  \n",
       "3     https://www.snopes.com/fact-check/belgium-mayo...  English  \n",
       "4     http://www.politifact.com/texas/statements/201...  English  \n",
       "...                                                 ...      ...  \n",
       "4447    https://www.snopes.com/fact-check/fire-plugged/  English  \n",
       "4448  http://www.politifact.com/wisconsin/statements...  English  \n",
       "4449  https://www.snopes.com/fact-check/the-cane-mut...  English  \n",
       "4450  http://www.politifact.com/ohio/statements/2010...  English  \n",
       "4451  http://www.politifact.com/punditfact/statement...  English  \n",
       "\n",
       "[24452 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#commencement des prétraitement :\n",
    "\n",
    "#import nécessaire :\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords') \n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "import unicodedata\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "#La j'ai mis que la colonne text en lower mais je crois qu'on devra tous les mettre par la suite\n",
    "df['text'] = df['text'].str.lower()\n",
    "\n",
    "\n",
    "#White spaces removal\n",
    "df['text'] = df['text'].str.strip()\n",
    "\n",
    "\n",
    "#Elimination des stopWord :\n",
    "#input_str = \"NLTK is a leading platform for building Python programs to work with human language data.\"\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "#La liste des stopwords en Anglais\n",
    "negation ={'haven''t','cannot',\"doesn't\",\"shouldn't\",\"needn't\",\"shant't\",\"weren't\",\"hasn't\", \"wasn't\",\"didn't\", \"aren't\",'not', \"mightn't\", \"mustn't\", 'no',  \"wouldn't\", \"mightn't\", \"won't\",  \"needn't\", \"wasn't\", \"wouldn't\",  \"isn't\", \"doesn't\", \"weren't\", \"isn't\", \"hasn't\", \"hadn't\", \"don't\", \"hadn't\",\"couldn't\"}\n",
    "\n",
    "#La liste des stopwords de négation en Anglais  \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "a= df['text'].str.replace(\"’\",\"'\") #Extraire toutes les entrées de la colonne text\n",
    "pat = r'\\b(?:{})\\b'.format('|'.join(negation))\n",
    "\n",
    "a=a.str.replace(pat,'not')\n",
    "pat='\\w*\\d\\w*'\n",
    "text_without_stopwords=[] #Une liste dont on va affecter les textes après l'élimination des stop words\n",
    "tk=TweetTokenizer()\n",
    "for text in a.iteritems(): #On parcourt toutes les lignes\n",
    " tokens = tk.tokenize(str(text[1]))\n",
    " result = [i for i in tokens if not i in stop_words-negation]\n",
    " splitor=\" \"\n",
    " concatinated = splitor.join(result) #concatiner les tokens\n",
    " text_without_stopwords.append(concatinated)\n",
    "\n",
    "df['text']=text_without_stopwords\n",
    "\n",
    "\n",
    "#The following code removes this set of symbols [!”#$%&’()*+,-./:;<=>?@[\\]^_`{|}~]:\n",
    "text_without_punctuation=[] # pour y mettre notre résultat\n",
    "a= df['text'] #Extraire toutes les entrées de la colonne text deja traiter pour faire la suite\n",
    "tk=TweetTokenizer()\n",
    "for text in a.iteritems(): #On parcourt toutes les lignes\n",
    "    result = re.sub('[!”#$%&’()*+,-./:;<=>?@[\\]^_`{|}~]', '', str(text[1]) )\n",
    "    splitor=\"\" #séparateur de mots\n",
    "    concatinated = splitor.join(result) #concatiner les résultats\n",
    "    text_without_punctuation.append(concatinated)\n",
    "\n",
    "df['text']=text_without_punctuation\n",
    "\n",
    "\n",
    "#The following code removes non ASCII characters :\n",
    "text_without_ascii=[] # pour y mettre notre résultat\n",
    "a= df['text'] #Extraire toutes les entrées de la colonne text deja traiter pour faire la suite\n",
    "tk=TweetTokenizer()\n",
    "for text in a.iteritems(): #On parcourt toutes les lignes\n",
    "    text = unicodedata.normalize('NFKD', str(text[1]) ).encode(\"ascii\", \"ignore\").decode(\"utf-8\", 'ignore')\n",
    "    splitor=\"\" #séparateur de mots\n",
    "    concatinated = splitor.join(text)\n",
    "    text_without_ascii.append(concatinated)\n",
    "\n",
    "df['text']=text_without_ascii\n",
    "\n",
    "\n",
    "#Lemmatization :\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "text_lemmatizer=[] # pour y mettre notre résultat\n",
    "a= df['text'] #Extraire toutes les entrées de la colonne text deja traiter pour faire la suite\n",
    "tk=TweetTokenizer()\n",
    "for ligne in a.iteritems(): #On parcourt toutes les lignes\n",
    "    wordList = re.sub(\"[^\\w]\", \" \",  ligne[1]).split() # on parcourt tout les mot de la ligne\n",
    "    newList=[]\n",
    "    for word in wordList:\n",
    "        if not(word.isdigit()): # si c'est  mot et non un nombre\n",
    "            newList.append(lemmatizer.lemmatize(word, pos = 'v')) #lemmatisation\n",
    "    splitor=\" \" #séparateur de mots\n",
    "    concatinated = splitor.join(newList)\n",
    "    text_lemmatizer.append(concatinated)\n",
    "\n",
    "df['text']=text_lemmatizer\n",
    "df\n",
    "\n",
    "#Correction orthographique:\n",
    "#from textblob import TextBlob ceci ne marche pas encore une installation est requise\n",
    "#df['text'][:5].apply(lambda x: str(TextBlob(x).correct())) \n",
    "\n",
    "#suppression des common word:\n",
    "from collections import Counter\n",
    "word_counter  = Counter()\n",
    "for sentence in df[\"text\"].values:\n",
    "    for word in sentence.split():\n",
    "        word_counter[word] += 1\n",
    "most = word_counter.most_common(10)\n",
    "print(\"most common word\"+str(most))\n",
    "print(\"Suppression of the common word de nos artiles : \")\n",
    "most_word = set([w for (w, wc) in most])\n",
    "def delmost_word(sentence):\n",
    "    return \" \".join([word for word in str(sentence).split() if word not in most_word])\n",
    "df[\"text\"] = df[\"text\"].apply(delmost_word)\n",
    "df[\"text\"].head()\n",
    "\n",
    "df\n",
    "\n",
    "#Fin des prétraitement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 3 : Conversion des textes en valeurs numériques\n",
    " On transforme nos données de textes en valeurs numériques, en utilisant des LabelEncoder sur les colonnes qu'on a  sauf la colonne texte et la colonne keyword, dont on a essayé Tf-IDF pour les transformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                              Candidate Biography\n",
      "1                                      Immigration\n",
      "2       canada, marijuana, world news daily report\n",
      "3                                            islam\n",
      "4                                    Congress,Guns\n",
      "                           ...                    \n",
      "4447              ASP Article, freakish fatalities\n",
      "4448                 Health Care,Medicaid,Medicare\n",
      "4449                        ASP Article, Petitions\n",
      "4450                         Government Efficiency\n",
      "4451                                         Islam\n",
      "Name: keywords, Length: 24452, dtype: object\n",
      "       act  actually  administration  allow  america  american  americans  \\\n",
      "0      0.0       0.0             0.0    0.0      0.0       0.0        0.0   \n",
      "1      0.0       0.0             0.0    0.0      0.0       0.0        0.0   \n",
      "2      0.0       0.0             0.0    0.0      0.0       0.0        0.0   \n",
      "3      0.0       0.0             0.0    0.0      0.0       0.0        0.0   \n",
      "4      0.0       0.0             0.0    0.0      0.0       0.0        0.0   \n",
      "...    ...       ...             ...    ...      ...       ...        ...   \n",
      "24447  0.0       0.0             0.0    0.0      0.0       0.0        0.0   \n",
      "24448  0.0       0.0             0.0    0.0      0.0       0.0        0.0   \n",
      "24449  0.0       0.0             0.0    0.0      0.0       0.0        0.0   \n",
      "24450  0.0       0.0             0.0    0.0      0.0       0.0        0.0   \n",
      "24451  0.0       0.0             0.0    0.0      0.0       0.0        0.0   \n",
      "\n",
      "       arrest  attack  average  ...  war  white  wisconsin  woman     women  \\\n",
      "0         0.0     0.0      0.0  ...  0.0    0.0        0.0    0.0  0.000000   \n",
      "1         0.0     0.0      0.0  ...  0.0    0.0        0.0    0.0  0.000000   \n",
      "2         0.0     0.0      0.0  ...  0.0    0.0        0.0    0.0  0.000000   \n",
      "3         0.0     0.0      0.0  ...  0.0    0.0        0.0    0.0  0.000000   \n",
      "4         0.0     0.0      0.0  ...  0.0    0.0        0.0    0.0  0.000000   \n",
      "...       ...     ...      ...  ...  ...    ...        ...    ...       ...   \n",
      "24447     0.0     0.0      0.0  ...  0.0    0.0        0.0    0.0  0.000000   \n",
      "24448     0.0     0.0      0.0  ...  0.0    0.0        0.0    0.0  0.000000   \n",
      "24449     0.0     0.0      0.0  ...  0.0    0.0        0.0    0.0  0.000000   \n",
      "24450     0.0     0.0      0.0  ...  0.0    0.0        0.0    0.0  0.000000   \n",
      "24451     0.0     0.0      0.0  ...  0.0    0.0        0.0    0.0  0.729838   \n",
      "\n",
      "       work  world  year     years  york  \n",
      "0       0.0    0.0   0.0  0.000000   0.0  \n",
      "1       0.0    0.0   0.0  0.000000   0.0  \n",
      "2       0.0    0.0   0.0  0.000000   0.0  \n",
      "3       0.0    0.0   0.0  0.000000   0.0  \n",
      "4       0.0    0.0   0.0  0.000000   0.0  \n",
      "...     ...    ...   ...       ...   ...  \n",
      "24447   0.0    0.0   0.0  0.000000   0.0  \n",
      "24448   0.0    0.0   0.0  0.000000   0.0  \n",
      "24449   0.0    0.0   0.0  0.000000   0.0  \n",
      "24450   0.0    0.0   0.0  0.661646   0.0  \n",
      "24451   0.0    0.0   0.0  0.000000   0.0  \n",
      "\n",
      "[24452 rows x 156 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chahinez\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n",
      "C:\\Users\\Chahinez\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: FutureWarning: The join_axes-keyword is deprecated. Use .reindex or .reindex_like on the result to achieve the same functionality.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#np.random.seed(500) #utilisé pour avoir le même résultat à chaque exécution \n",
    "#On crée des variable LabelEncoder qui vont servir à transférer nos données en valeurs numériques\n",
    "l1=LabelEncoder()\n",
    "l2=LabelEncoder()\n",
    "l3=LabelEncoder()\n",
    "l4=LabelEncoder()\n",
    "l5=LabelEncoder()\n",
    "l6=LabelEncoder()\n",
    "l7=LabelEncoder()\n",
    "l8=LabelEncoder()\n",
    "l9=LabelEncoder()\n",
    "l10=LabelEncoder()\n",
    "l11=LabelEncoder()\n",
    "l12=LabelEncoder()\n",
    "l13=LabelEncoder()\n",
    "df=df.applymap(str) #on transforme tous nous données en String car y'avais des entrées qui ont une combinaison du string et float\n",
    "#On applique la mesure TF-IDF sur la colonne text et la colonne keywords\n",
    "Tfidf_vect = TfidfVectorizer(max_features=1000,sublinear_tf=True, min_df=200, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "tfidfx=Tfidf_vect.fit_transform(df['text'])\n",
    "df1 = pd.DataFrame(tfidfx.toarray(), columns=Tfidf_vect.get_feature_names())\n",
    "Tfidf_vect = TfidfVectorizer(max_features=30)\n",
    "print(df['keywords'])\n",
    "tfidfx=Tfidf_vect.fit_transform(df['keywords'])\n",
    "df2 = pd.DataFrame(tfidfx.toarray(), columns=Tfidf_vect.get_feature_names())\n",
    "print(df1)\n",
    "\n",
    "\n",
    "#on transfère toutes les valeurs des colonnes qu'on va utiliser en valeurs numériques \n",
    "df['id']=l1.fit_transform(df['id'])\n",
    "df['date']=l3.fit_transform(df['date'])\n",
    "df['author']=l5.fit_transform(df['author'])\n",
    "df['headline']=l6.fit_transform(df['headline'])\n",
    "df['named_entities_claim']=l7.fit_transform(df['named_entities_claim'])\n",
    "df['named_entities_article']=l8.fit_transform(df['named_entities_article'])\n",
    "df['source']=l10.fit_transform(df['source'])\n",
    "df['sourceURL']=l11.fit_transform(df['sourceURL'])\n",
    "df['link']=l12.fit_transform(df['link'])\n",
    "df['language']=l13.fit_transform(df['language'])\n",
    "\n",
    "training1= pd.concat([df, df1], axis=1,join_axes=[df.index])\n",
    "training=pd.concat([training1, df2], axis=1,join_axes=[df.index])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 4 : Dévision du jeu de données en données d'entraînement et données de test\n",
    "On mélange le dataframe qu'on a et après on sélectionne 80% des données pour l'entraînement et 20% pour le test, ensuite on sélectionne les colonnes features dont on s'intéresse lors du classification, et on essaye plusieurs combinaisons de colonnes pour arriver à une meilleure accuracy (#TODO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                               text  date  \\\n",
      "9553  23116  germany release historic statement denounce unite  3737   \n",
      "2632   7641  muslims disturb plan come grocery store go bar...  3048   \n",
      "3831  19599         photograph halfblack halftabby chimera cat  3737   \n",
      "6993   6601  new rasmussen poll people oppose sotomayor con...   379   \n",
      "2305   1441  unite airlines flight attendant slap cry baby ...  2911   \n",
      "...     ...                                                ...   ...   \n",
      "4650  22476      barack plan call mandate fin small businesses   256   \n",
      "9315  11704  send much interest china pay entire people lib...  1113   \n",
      "1638  20185  rick perry never lose election remain person t...   961   \n",
      "1627   6632  minnesota public school make learn arabic mand...  3737   \n",
      "9500  11848  upwards women seek abortion decide abortion se...  1645   \n",
      "\n",
      "     truthRating ratingName  author  headline  named_entities_claim  \\\n",
      "9553           2    MIXTURE    3716      5242                  9857   \n",
      "2632           2    MIXTURE    1254      9398                 21840   \n",
      "3831           3       True    3716      3197                 19102   \n",
      "6993           2    MIXTURE    1876     17606                 14174   \n",
      "2305           1      False    2674      8917                 15881   \n",
      "...          ...        ...     ...       ...                   ...   \n",
      "4650           1      False    1829     20217                 14291   \n",
      "9315           1      False    2457     14731                 23701   \n",
      "1638           2    MIXTURE    3482     21037                  7855   \n",
      "1627           1      False    3716      5558                  9112   \n",
      "9500           1      False    2907     15201                  6480   \n",
      "\n",
      "      named_entities_article  \\\n",
      "9553                    9560   \n",
      "2632                    9560   \n",
      "3831                    8980   \n",
      "6993                    9560   \n",
      "2305                    8411   \n",
      "...                      ...   \n",
      "4650                    1067   \n",
      "9315                    7165   \n",
      "1638                    7506   \n",
      "1627                    9560   \n",
      "9500                    8719   \n",
      "\n",
      "                                               keywords  ...  war  white  \\\n",
      "9553  geopolitics, germany, trump administration, un...  ...  0.0    0.0   \n",
      "2632                              Environment,Fake news  ...  0.0    0.0   \n",
      "3831                               animals, ASP Article  ...  0.0    0.0   \n",
      "6993                 Sotomayor Nomination,Supreme Court  ...  0.0    0.0   \n",
      "2305                                          Fake news  ...  0.0    0.0   \n",
      "...                                                 ...  ...  ...    ...   \n",
      "4650                                        Health Care  ...  0.0    0.0   \n",
      "9315              China,Deficit,Foreign Policy,Military  ...  0.0    0.0   \n",
      "1638                                Candidate Biography  ...  0.0    0.0   \n",
      "1627                                                nan  ...  0.0    0.0   \n",
      "9500       Abortion,Children,Families,Health Care,Women  ...  0.0    0.0   \n",
      "\n",
      "      wisconsin  woman  women  work  world      year  years     york  \n",
      "9553        0.0    0.0    0.0   0.0    0.0  0.000000    0.0  0.00000  \n",
      "2632        0.0    0.0    0.0   0.0    0.0  0.000000    0.0  0.00000  \n",
      "3831        0.0    0.0    0.0   0.0    0.0  0.000000    0.0  0.00000  \n",
      "6993        0.0    0.0    0.0   0.0    0.0  0.000000    0.0  0.47812  \n",
      "2305        0.0    0.0    0.0   0.0    0.0  0.000000    0.0  0.00000  \n",
      "...         ...    ...    ...   ...    ...       ...    ...      ...  \n",
      "4650        0.0    0.0    0.0   0.0    0.0  0.000000    0.0  0.00000  \n",
      "9315        0.0    0.0    0.0   0.0    0.0  0.000000    0.0  0.00000  \n",
      "1638        0.0    0.0    0.0   0.0    0.0  0.636146    0.0  0.00000  \n",
      "1627        0.0    0.0    0.0   0.0    0.0  0.000000    0.0  0.00000  \n",
      "9500        0.0    0.0    1.0   0.0    0.0  0.000000    0.0  0.00000  \n",
      "\n",
      "[19562 rows x 170 columns]\n",
      "  (0, 3)\t0.7071067811865475\n",
      "  (0, 5)\t0.7071067811865475\n",
      "  (1, 19)\t1.0\n",
      "  (2, 23)\t1.0\n",
      "  (4, 16)\t1.0\n",
      "  (5, 22)\t1.0\n",
      "  (6, 28)\t0.6232989561929475\n",
      "  (6, 1)\t0.40899010475746245\n",
      "  (6, 2)\t0.40899010475746245\n",
      "  (6, 23)\t0.5262628617238174\n",
      "  (7, 12)\t1.0\n",
      "  (8, 23)\t1.0\n",
      "  (9, 15)\t1.0\n",
      "  (10, 29)\t0.5681503904455378\n",
      "  (10, 8)\t0.5941753078092485\n",
      "  (10, 12)\t0.5693512425791021\n",
      "  (14, 1)\t0.7071067811865476\n",
      "  (14, 2)\t0.7071067811865476\n",
      "  (17, 28)\t0.6232989561929475\n",
      "  (17, 1)\t0.40899010475746245\n",
      "  (17, 2)\t0.40899010475746245\n",
      "  (17, 23)\t0.5262628617238174\n",
      "  (18, 28)\t0.6232989561929475\n",
      "  (18, 1)\t0.40899010475746245\n",
      "  (18, 2)\t0.40899010475746245\n",
      "  :\t:\n",
      "  (24433, 9)\t1.0\n",
      "  (24434, 29)\t0.6911011767414377\n",
      "  (24434, 8)\t0.7227580255566868\n",
      "  (24435, 1)\t0.7071067811865476\n",
      "  (24435, 2)\t0.7071067811865476\n",
      "  (24436, 27)\t1.0\n",
      "  (24437, 1)\t0.7071067811865476\n",
      "  (24437, 2)\t0.7071067811865476\n",
      "  (24438, 11)\t1.0\n",
      "  (24439, 24)\t0.7065302640249692\n",
      "  (24439, 14)\t0.707682828685851\n",
      "  (24440, 6)\t0.7236240186245134\n",
      "  (24440, 17)\t0.6901943781788648\n",
      "  (24441, 1)\t0.7071067811865476\n",
      "  (24441, 2)\t0.7071067811865476\n",
      "  (24444, 1)\t0.7071067811865476\n",
      "  (24444, 2)\t0.7071067811865476\n",
      "  (24445, 18)\t1.0\n",
      "  (24447, 1)\t0.7071067811865476\n",
      "  (24447, 2)\t0.7071067811865476\n",
      "  (24448, 6)\t0.7236240186245134\n",
      "  (24448, 17)\t0.6901943781788648\n",
      "  (24449, 1)\t0.7071067811865476\n",
      "  (24449, 2)\t0.7071067811865476\n",
      "  (24450, 15)\t1.0\n",
      "9553    2\n",
      "2632    2\n",
      "3831    3\n",
      "6993    2\n",
      "2305    1\n",
      "       ..\n",
      "4650    1\n",
      "9315    1\n",
      "1638    2\n",
      "1627    1\n",
      "9500    1\n",
      "Name: truthRating, Length: 19562, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "#on mélange le dataframe\n",
    "shuffled=shuffle(training1)\n",
    "#on sélectionne 80% de notre jeu de données pour l'entrainement\n",
    "training=shuffled.head(19562)\n",
    "#on sélectionne 20% de notre jeu de données pour le test\n",
    "testing=shuffled.tail(4890)\n",
    "#les catégories de chaque entrée des données d'entrainement\n",
    "value=training['truthRating']\n",
    "print(training)\n",
    "#les catégories réels de chaque entrée des données du test\n",
    "realvalues=testing['truthRating']\n",
    "#on élimine les colonnes des catégories (car le modèle va les prédir)\n",
    "training=training.drop(columns='ratingName')\n",
    "testing=testing.drop(columns='ratingName')\n",
    "training=training.drop(columns='named_entities_claim')\n",
    "testing=testing.drop(columns='named_entities_claim')\n",
    "training=training.drop(columns='named_entities_article')\n",
    "testing=testing.drop(columns='named_entities_article')\n",
    "training=training.drop(columns='truthRating')\n",
    "testing=testing.drop(columns='truthRating')\n",
    "training=training.drop(columns='id')\n",
    "testing=testing.drop(columns='id')\n",
    "training=training.drop(columns='headline')\n",
    "testing=testing.drop(columns='headline')\n",
    "training=training.drop(columns='link')\n",
    "testing=testing.drop(columns='link')\n",
    "testing=testing.drop(columns='keywords')\n",
    "training=training.drop(columns='keywords')\n",
    "training=training.drop(columns='date')\n",
    "testing=testing.drop(columns='date')\n",
    "print(tfidfx)\n",
    "print(value)\n",
    "training=training.drop(columns='text')\n",
    "testing=testing.drop(columns='text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 5 :  Entraînement et prédiction en utilisant des modèles de classification\n",
    "On passe les features et targets des données d'entraînement à nos classifiers (#TODO tester plusieurs classifieurs) et après on lui laisse prédire les valeurs des données de test (soit vrai, faux ou mixture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2' '1' '1' ... '1' '2' '2']\n",
      "0.49427402862985687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "\n",
    "\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(training,value)\n",
    "result=Naive.predict(testing)\n",
    "print(result)\n",
    "print(accuracy_score(realvalues,result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
